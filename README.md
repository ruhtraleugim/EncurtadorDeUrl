# Encurtador de URL 

√â a minha vis√£o do **porqu√™** e **das decis√µes que tomei** para que o encurtador funcione em alt√≠ssima escala, 24/7, por 10 anos, com URLs extremamente curtas.

---

## üéØ Objetivo do sistema
Criar um encurtador de URL que opere sem interrup√ß√£o, capaz de lidar com **100 milh√µes de novas URLs por dia**, e que mantenha tudo salvo por **10 anos**, sem perder performance, sem gerar colis√µes e mantendo as URLs curtas.

---

## üß† Decis√µes principais

### 1. **Charset definido: Base62 (0‚Äì9, a‚Äìz, A‚ÄìZ)**
Decidi usar Base62 porque √© o conjunto mais compacto poss√≠vel que ainda √© universalmente compat√≠vel e n√£o causa problema em nenhum navegador.
Isso tamb√©m maximiza o espa√ßo de combina√ß√µes.

### 2. **Tamanho do c√≥digo curto: 7 caracteres**
N√£o escolhi 7 √† toa.
Com 100M novas URLs por dia durante 10 anos, teremos **365 bilh√µes de c√≥digos**.

- 62^6 n√£o aguenta isso.
- 62^7 aguenta com sobra ‚Äî ent√£o essa foi a escolha natural.

Decis√£o: Comprimento variavel come√ßando em 5 caracteres indo at√© 7; pois evita que "chutem as urls".

### 3. **Banco de dados: Cassandra / ScyllaDB**
Escolhi Cassandra porque:
- escala horizontal praticamente infinita;
- escrita barata e distribu√≠da (e n√≥s teremos MUITA escrita);
- leitura r√°pida quando combinada com cache;
- toler√¢ncia a falhas absurda.

Postgres sharded seria poss√≠vel, mas muito mais caro e fr√°gil para o tr√°fego esperado.

### 4. **Cache pesado para leitura: Redis + CDN**
Como a propor√ß√£o √© **1 grava√ß√£o para 10 leituras**, fica obvio que:
- N√£o podemos ir ao banco para cada GET.
- A CDN deve responder a maior parte dos redirecionamentos.
- Redis entra como cache quente para os misses.

### 5. **Armazenamento por 10 anos**
O total de dados brutos chega facilmente acima de **100 TB**.
Por isso, a decis√£o foi:
- dados recentes ficam no banco principal;
- dados antigos v√£o para armazenamento frio ‚Äî mas sem perder a capacidade de restaurar quando necess√°rio.

### 6. **API simples e direta**
Endpoint principal: `POST /api/v1/shorten`.
Sem complica√ß√£o.
Apenas recebe uma URL, valida e retorna o c√≥digo curto.

### 7. **Valida√ß√£o: m√°ximo 100 bytes**
Decidi impor esse limite porque:
- evita payload gigante;
- mant√©m o sistema previs√≠vel;
- ajuda no armazenamento e indexa√ß√£o.

### 8. **Pol√≠tica de TTL: 10 anos fixos**
O sistema aceita TTL menor, mas nunca maior.
Isso garante consist√™ncia e permite controlar o ciclo de vida dos dados.

### 9. **Gera√ß√£o de c√≥digo: contador distribu√≠do + Base62**
Nada de aleatoriedade.
Aleat√≥rio √© f√°cil, mas gera colis√µes e exige lock ou checagem.
Decidi por algo determin√≠stico:
- contador global shardeado;
- convers√£o para Base62;
- prefixo impl√≠cito por worker, se necess√°rio.

Resultado: gera√ß√£o est√°vel, sem colis√£o e com throughput absurdo.

### 10. **Observabilidade obrigat√≥ria**
Decidi que o sistema s√≥ √© aceit√°vel se tiver:
- logs estruturados;
- m√©tricas de lat√™ncia e taxa de erro;
- alertas de tr√°fego an√¥malo;
- tracing distribu√≠do.

Sem isso, n√£o d√° pra operar algo que funciona 24/7.

---

## üîê Decis√µes sobre seguran√ßa

### üîí Como cada prote√ß√£o ser√° implementada

#### **1. Rate Limit distribu√≠do (prote√ß√£o contra flood)**
Decis√£o: usar **Token Bucket distribu√≠do em Redis**.
- Cada IP recebe um "balde" com X requisi√ß√µes por segundo.
- A cada encurtamento, o sistema tenta consumir 1 token.
- Se o balde estiver vazio ‚Üí `429 Too Many Requests`.
- Redis garante opera√ß√µes at√¥micas e funciona em cluster.

**Protege contra:** bots, automa√ß√£o agressiva e gera√ß√£o em massa de URLs.

---

#### **2. Filtro contra URLs maliciosas (anti-phishing e anti-malware)**
Pipeline de valida√ß√£o com m√∫ltiplas camadas:
1. Regex b√°sico para validar formato.
2. Bloqueio de esquemas perigosos: `javascript:`, `data:`, `file:`.
3. Verifica√ß√£o de dom√≠nios suspeitos (blocklist).
4. Integra√ß√£o com APIs de seguran√ßa (Google Safe Browsing / Cloudflare Security).
5. Normaliza√ß√£o da URL (remover unicode invis√≠vel, espa√ßos, caracteres suspeitos).

**Protege contra:** malware, phishing, golpes e explora√ß√£o via links.

O unico problema ainda √© o usuario.

---

#### **3. Bloqueio autom√°tico de padr√µes suspeitos (detec√ß√£o de abuso)**
Sistema de heur√≠stica + regras autom√°ticas:
- explos√£o s√∫bita de requisi√ß√µes por IP;
- URLs muito parecidas sendo criadas em massa (indicador de automa√ß√£o);
- par√¢metros ofuscados ou padr√µes de spam;
- repeti√ß√£o de URLs para dom√≠nios com m√° reputa√ß√£o.

A√ß√µes autom√°ticas:
- bloqueio de IP tempor√°rio;
- aumento de rate limit para o infrator (ban progressivo);
- marca√ß√£o de dom√≠nio como suspeito;
- exig√™ncia de captcha;
- alerta enviado para observabilidade.

**Protege contra:** spam, abuso automatizado, ataques, explora√ß√£o do encurtador.

---
- rate limit: n√£o d√° para algu√©m disparar milh√µes de encurtamentos por minuto;
- filtro contra URLs maliciosas;
- bloqueio autom√°tico de padr√µes suspeitos.

Sistema robusto exige prote√ß√£o contra abuso.

---

## üåê Decis√£o de Roteamento: CDN na frente sempre
O GET /{code} nunca deveria bater diretamente no backend.
Decis√£o: toda resolu√ß√£o passa por CDN (Cloudflare, AWS CloudFront ou similar).

---

## üõ† Por que Java + Spring?
- confi√°vel;
- est√°vel sob carga extrema;
- f√°cil de escalar;
- ecossistema maduro para observabilidade e seguran√ßa.

Com o tr√°fego esperado, Node/Express ou Python/Django sofreriam muito mais.

---

## üöÄ Resumo da vis√£o final
Este encurtador n√£o √© um "projetinho".
Ele foi pensado para durar **10 anos**, com **centenas de bilh√µes** de registros, funcionando **sem cair** e respondendo em **milissegundos**.

Tudo aqui foi decidido com foco em:
- escala;
- disponibilidade;
- baixo custo por opera√ß√£o;
- simplicidade operacional;
- robustez.
